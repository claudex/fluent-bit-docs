
The **content_modifier** processor allows you to manipulate the metadata/attributes and content of Logs and Traces.

Similar to the functionality exposed by filters, this processor presents a unified mechanism to perform such operations for data manipulation. The most significant difference is that processors perform better than filters, and when chaining them, there are no encoding/decoding performance penalties.

> Note that processors and this specific component can only be enabled using the new YAML configuration format. Classic mode configuration format doesn't support processors.

To configure this processor there are two basic concepts that needs to be understood: context and actions.

### Context

The context defines `where` the actions will be applied. Depending of the telemetry signal being processed, different context are available:

#### Log contexts

Every record in Fluent Bit can be sim

| name | description |
| :-- | :-- |
| attributes | the log record contains the attributes (metadata) and the body of the message. By setting the context to `attributes` it performs the action or the attributes associated with the log record. |
| body |  the `body` context refers to the content of the message in the log record, all actions will be applied to the message content. |

__OpenTelemetry Log Contexts__

If you are receiving native OpenTelemetry Logs through the [OpenTelemetry input plugin](), or if the content is being generated from other plugins that packages the content in OpenTelemetry Logs schema, you can use the following additional contexts to operate on Resources and Spans. The following is a list of the supported contexts for OpenTelemetry Logs:

| name | description |
| :-- | :-- |
| otel_resource_attributes | modify the Resource attributes |
| otel_scope_name |  manipulate the Scope name |
| otel_scope_version | manipulate the scope version |
| otel_scope_attributes | modify the Scope attributes |

## Configuration Parameters

Below is a summary of the supported configuration parameters

| Key         | Description |
| :---------- | :--- |
| action | Define the operation to run on the target content. This field is mandatory; for more details about the actions available, check the table below. |
| context | Specify which component of the Telemetry type will be affected. When processing Logs the following contexts are available: for Logs `attributes` and `body`, for OpenTelemetry Logs `otel_resource_attributes`, `otel_scope_name`, `otel_scope_version` and `otel_scope_attributes` . When processing Traces the following contexts are available: `span_name`, `span_kind`, `span_status`, `span_attributes`. |
| key | Specify the name of the key that will be used to apply the modification. |
| value | Based on the action type, `value` might required and represent different things. Check the detailed information for the specific actions. |
| pattern | Defines a regular expression pattern. This property is only used by the `extract` action. |
| converted_type | Define the data type to perform the conversion, the available options are: `string`, `boolean`, `int` and `double` . |

### Actions

The actions specify the type of operation to run on top of a specific key or content from a Log or a Trace. The following actions are available:

| Action  | Description                                                  |
| ------- | ------------------------------------------------------------ |
| insert  | Insert a new key with a value into the target context. The `key` and `value` parameters are required. |
| upsert  | Given a specific key with a value, the `upsert` operation will try to update the value of the key. If the key does not exist, the key will be created. The `key` and `value` parameters are required. |
| delete  | Delete a key from the target context. The `key` parameter is required. |
| rename  | Change the name of a key. The `value` set in the configuration will represent the new name. The `key` and `value` parameters are required. |
| hash    | Replace the key value with a hash generated by the SHA-256 algorithm, the binary value generated is finally set as an hex string representation. The `key` parameter is required. |
| extract | Allows to extact the value of a single key as a list of key/value pairs. This action needs the configuration of a regular expression in the  `pattern` property . The `key` and `pattern` parameters are required.  For more details check the examples below. |
| convert | Convert the data type of a key value. The `key` and `converted_type` parameters are required. |

#### Insert example

The following example appends the key `color` with the value `blue` to the log stream.

```yaml
pipeline:
  inputs:
    - name: dummy
      dummy: '{"key1": "123.4"}'

      processors:
        logs:
          - name: content_modifier
            action: insert
            key: "color"
            value: "blue"
  outputs:
    - name : stdout
      match: '*'
      format: json_lines
```

#### Upsert example

Update the value of `key1` and insert `key2`:

```yaml
pipeline:
  inputs:
    - name: dummy
      dummy: '{"key1": "123.4"}'

      processors:
        logs:
          - name: content_modifier
            action: upsert
            key: "key1"
            value: "5678"

          - name: content_modifier
            action: upsert
            key: "key2"
            value: "example"

  outputs:
    - name : stdout
      match: '*'
      format: json_lines

```


#### Delete example

Delete `key2` from the stream:

```yaml
pipeline:
  inputs:
    - name: dummy
      dummy: '{"key1": "123.4", "key2": "example"}'

      processors:
        logs:
          - name: content_modifier
            action: delete
            key: "key2"

  outputs:
    - name : stdout
      match: '*'
      format: json_lines
```

#### Rename example

Change the name of `key2` to `test`:

```yaml
pipeline:
  inputs:
    - name: dummy
      dummy: '{"key1": "123.4", "key2": "example"}'

      processors:
        logs:
          - name: content_modifier
            action: rename
            key: "key2"
            value: "test"

  outputs:
    - name : stdout
      match: '*'
      format: json_lines
```

#### Hash example

Apply the SHA-256 algorithm for the value of the key `password`:

```yaml
pipeline:
  inputs:
    - name: dummy
      dummy: '{"username": "bob", "password": "12345"}'

      processors:
        logs:
          - name: content_modifier
            action: hash
            key: "password"

  outputs:
    - name : stdout
      match: '*'
      format: json_lines
```



#### Extract example

By using a domain address, perform a extraction of the components of it as a list of key value pairs:

```yaml
pipeline:
  inputs:
    - name: dummy
      dummy: '{"http.url": "https://fluentbit.io/docs?q=example"}'

      processors:
        logs:
          - name: content_modifier
            action: extract
            key: "http.url"
            pattern: ^(?<http_protocol>https?):\/\/(?<http_domain>[^\/\?]+)(?<http_path>\/[^?]*)?(?:\?(?<http_query_params>.*))?

  outputs:
    - name : stdout
      match: '*'
      format: json_lines
```



#### Convert example

Both keys in the example are strings. Convert the `key1` to a double/float type and `key2` to a boolean:

```yaml
pipeline:
  inputs:
    - name: dummy
      dummy: '{"key1": "123.4", "key2": "true"}'

      processors:
        logs:
          - name: content_modifier
            action: convert
            key: key1
            converted_type: int

          - name: content_modifier
            action: convert
            key: key2
            converted_type: boolean

  outputs:
    - name : stdout
      match: '*'
      format: json_lines
```
